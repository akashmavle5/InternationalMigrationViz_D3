{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import log\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ross/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "# Load reference datasets\n",
    "countries  = pd.read_csv('../raw_data/CountriesList.txt', delimiter=' , ', index_col='Country Code')\n",
    "\n",
    "latlong = pd.read_csv('../raw_data/LatLong.csv', index_col='Alpha-3',\n",
    "                      usecols=['Alpha-3', 'lat', 'long'])\n",
    "\n",
    "good_indices = (countries.index & latlong.index)\n",
    "\n",
    "iso_codes = pd.read_csv('../raw_data/ISO_codes.csv', index_col='country-code')\n",
    "def num_to_alpha3(num_code): return iso_codes.loc[num_code, 'alpha-3']\n",
    "\n",
    "# Load population dataset\n",
    "label_cols = ['Country Name', 'Country Code']\n",
    "year_cols = ['1990', '1995', '2000', '2005', '2010', '2015']\n",
    "keep_cols = label_cols + year_cols\n",
    "pop = pd.read_csv('../raw_data/Population.csv',\n",
    "                  index_col='Country Code', usecols=keep_cols)\n",
    "pop = pop.reindex(pop.index & good_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bad_cols = ['Destination', 'Numeric', 'Data Type', 'Total', 'Other North', 'Other South']\n",
    "\n",
    "def get_migrate_df(year):\n",
    "    df = pd.read_excel('../raw_data/Migrate_'+year+'.xlsx', header=0)\n",
    "    \n",
    "    df = df.query('Numeric < 900 and Numeric != 830')\n",
    "    df['Country Code'] = df['Numeric'].apply(num_to_alpha3)\n",
    "    df.set_index('Country Code', inplace=True)\n",
    "    df = df.reindex(df.index & pop[year].dropna().index)\n",
    "    \n",
    "    good_countries = set(df['Destination'])\n",
    "    \n",
    "    for ccol in df.columns[6:]:\n",
    "        if ccol not in good_countries:\n",
    "            df.drop(ccol, axis=1, inplace=True)\n",
    "        else:\n",
    "            df.rename(columns={ccol: df.index[df['Destination'] == ccol][0]}, inplace=True)\n",
    "    \n",
    "    return df.drop(bad_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting im_ & em_ df's for:  1990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ross/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(168, 168) (168, 168) 5018098.0\n",
      "Getting im_ & em_ df's for:  1995\n",
      "(168, 168) (168, 168) 6602801.0\n",
      "Getting im_ & em_ df's for:  2000\n",
      "(168, 168) (168, 168) 9177487.0\n",
      "Getting im_ & em_ df's for:  2005\n",
      "(168, 168) (168, 168) 10309054.0\n",
      "Getting im_ & em_ df's for:  2010\n",
      "(168, 168) (168, 168) 11566960.0\n",
      "Getting im_ & em_ df's for:  2015\n",
      "(167, 167) (167, 167) 12050031.0\n"
     ]
    }
   ],
   "source": [
    "immigrants = {}\n",
    "emigrants = {}\n",
    "maxs = {}\n",
    "\n",
    "for year in year_cols:\n",
    "    print(\"Getting im_ & em_ df's for: \", year)\n",
    "    \n",
    "    immigrants[year] = get_migrate_df(year)\n",
    "    maxs[year] = immigrants[year].max().max()\n",
    "    emigrants[year] = immigrants[year].transpose()\n",
    "    \n",
    "    print(immigrants[year].shape, emigrants[year].shape, immigrants[year].max().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.6546467349417"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = migrate['1995'].drop(bad_cols, axis=1)\n",
    "from math import log\n",
    "log(test.max().max(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Scaler():\n",
    "    def __init__(self, oldrange, newrange):\n",
    "        self.oldmin = oldrange[0]\n",
    "        self.oldrange = oldrange[1] - oldrange[0]\n",
    "        self.newmin = newrange[0]\n",
    "        self.newrange = newrange[1] - oldrange[0]\n",
    "        \n",
    "    def __call__(self, value):\n",
    "        return (((value - self.oldmin)*self.newrange) / self.oldrange) + self.newmin\n",
    "\n",
    "def single_arc(origin, destination, status, strokeWidth):\n",
    "    d = {}\n",
    "    d['origin'] = {'latitude': latlong.loc[origin]['lat'],\n",
    "                   'longitude': latlong.loc[origin]['long']}\n",
    "    d['destination'] = {'latitude': latlong.loc[destination]['lat'],\n",
    "                        'longitude': latlong.loc[destination]['long']}\n",
    "    d['strokeWidth'] = strokeWidth\n",
    "    \n",
    "    if status == 'im':\n",
    "        d['strokeColor'] = 'green'\n",
    "    elif status == 'em':\n",
    "        d['strokeColor'] = 'red'\n",
    "    \n",
    "    return d\n",
    "\n",
    "def row_arcs(row_name, row, status, scaler):\n",
    "    if status == 'im':\n",
    "        # for immigration, row_name = destination  \n",
    "        l = [single_arc(origin, row_name, status, scaler(value)) for origin, value in row.items()]\n",
    "    elif status == 'em':\n",
    "        # for emigration, row_name = origin\n",
    "        l = [single_arc(row_name, destination, status, scaler(value)) for destination, value in row.items()]\n",
    "            \n",
    "    return l\n",
    "\n",
    "# threshold: we only count arcs where (num_people > threshold)\n",
    "def df_arcs(df, status, threshold, maximum):\n",
    "    assert status in ['im', 'em']\n",
    "    # second parameter of Scaler sets the range for strokeWidth\n",
    "    scaler = Scaler([0, maximum], [0.1, 8])\n",
    "    d = {}\n",
    "    if status == 'im':\n",
    "        for code, row in df.iterrows():\n",
    "            d[code] = row_arcs(code, row[row > threshold], 'im', scaler)\n",
    "    elif status == 'em':\n",
    "        for code, row in df.iterrows():\n",
    "            d[code] = row_arcs(code, row[row > threshold], 'em', scaler)\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "im_arcs = {}\n",
    "em_arcs = {}\n",
    "\n",
    "for year in year_cols:\n",
    "    # could also just pass absolute max instead of by year ?\n",
    "    im_arcs[year] = df_arcs(immigrants[year], 'im', 1000, maxs[year])\n",
    "    em_arcs[year] = df_arcs(emigrants[year], 'em', 1000, maxs[year])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('../processed_data/immigrant_arcs.json', 'w') as out:\n",
    "    json.dump(im_arcs, out, indent=2)\n",
    "    \n",
    "with open('../processed_data/emigrant_arcs.json', 'w') as out:\n",
    "    json.dump(em_arcs, out, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_scaler = Scaler([0,100], [0,10])\n",
    "test_scaler(75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
